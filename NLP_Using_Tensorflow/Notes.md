# NLP Using Tensorflow

    Tokenization:
        The process of representing words in a way that a computer can process them with a view to later training a neural network that can understand their meaning is called tokenization.

    